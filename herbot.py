from langchain_community.document_loaders import PyPDFLoader
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from dotenv import load_dotenv, find_dotenv
import streamlit as st
import time

_ = load_dotenv(find_dotenv())

# ou outro modelo de sua preferÃªncia
chat = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.2)


def resposta_bot(mensagens, documento, max_retries=3):
    mensagem_system = '''VocÃª Ã© um assistente amigÃ¡vel chamado HerBot. VocÃª sÃ³ pode responder EXCLUSIVAMENTE com base nessa fonte de dados: {informacoes}.
  Caso seja feita alguma pergunta fora do contexto, vocÃª deve se desculpar e dizer que nÃ£o sabe'''
    mensagens_modelo = [('system', mensagem_system)]
    mensagens_modelo += mensagens
    template = ChatPromptTemplate.from_messages(mensagens_modelo)
    chain = template | chat

    for retry in range(max_retries):
        try:
            return chain.invoke({'informacoes': documento}).content
        except Exception as e:
            print(
                f"Erro na chamada da API (tentativa {retry + 1}/{max_retries}): {e}")
            if retry < max_retries - 1:
                # Espera exponencial antes de tentar novamente
                time.sleep(2 ** retry)
            else:
                return "Desculpe, nÃ£o consegui obter uma resposta da API apÃ³s vÃ¡rias tentativas."


def carrega_pdf():
    caminho = 'files/BaseDadosShakes.pdf'
    loader = PyPDFLoader(caminho)
    lista_documentos = loader.load()
    documento = ''
    for doc in lista_documentos:
        documento = documento + doc.page_content
    return documento


# ConfiguraÃ§Ã£o da pÃ¡gina Streamlit
st.set_page_config(page_title='HerBot Chat')
st.header("ðŸ¤–Bem vindo ao Herbot", divider=True)

# InicializaÃ§Ã£o das mensagens na sessÃ£o
if 'mensagens' not in st.session_state:
    st.session_state.mensagens = []

# ExibiÃ§Ã£o das mensagens anteriores
for mensagem in st.session_state.mensagens:
    with st.chat_message(mensagem['role']):
        st.markdown(mensagem['content'])

# Input do usuÃ¡rio
if prompt := st.chat_input("FaÃ§a sua pergunta:"):
    # Adiciona a mensagem do usuÃ¡rio ao histÃ³rico
    st.session_state.mensagens.append({'role': 'user', 'content': prompt})
    with st.chat_message('user'):
        st.markdown(prompt)

    # Exibe um indicador de que o bot estÃ¡ "digitando"
    with st.chat_message('assistant'):
        typing_message = st.empty()  # Placeholder para a mensagem temporÃ¡ria
        typing_message.markdown("digitando...")

    # Carrega o PDF e obtÃ©m a resposta do bot
    documento = carrega_pdf()
    resposta = resposta_bot(st.session_state.mensagens, documento)

    # Substitui o indicador pela resposta final
    typing_message.markdown(resposta)

    # Adiciona a resposta do bot ao histÃ³rico
    st.session_state.mensagens.append(
        {'role': 'assistant', 'content': resposta})
